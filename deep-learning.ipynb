{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (4.31.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from transformers) (4.66.0)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: lightning in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (2.0.7)\n",
      "Requirement already satisfied: Jinja2<5.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (3.1.2)\n",
      "Requirement already satisfied: PyYAML<8.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (6.0.1)\n",
      "Requirement already satisfied: arrow<3.0,>=1.2.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (1.2.3)\n",
      "Requirement already satisfied: backoff<4.0,>=2.2.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (4.11.1)\n",
      "Requirement already satisfied: click<10.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (8.1.6)\n",
      "Requirement already satisfied: croniter<1.5.0,>=1.3.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (1.4.1)\n",
      "Requirement already satisfied: dateutils<2.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (0.6.12)\n",
      "Requirement already satisfied: deepdiff<8.0,>=5.7.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (6.3.1)\n",
      "Requirement already satisfied: fastapi<2.0,>=0.92.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (0.103.0)\n",
      "Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (2023.6.0)\n",
      "Requirement already satisfied: inquirer<5.0,>=2.10.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (3.1.3)\n",
      "Requirement already satisfied: lightning-cloud>=0.5.37 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (0.5.37)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (0.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (1.22.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (23.1)\n",
      "Requirement already satisfied: psutil<7.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (5.9.0)\n",
      "Requirement already satisfied: pydantic<2.2.0,>=1.7.4 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (2.1.1)\n",
      "Requirement already satisfied: python-multipart<2.0,>=0.0.5 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (0.0.6)\n",
      "Requirement already satisfied: requests<4.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (2.31.0)\n",
      "Requirement already satisfied: rich<15.0,>=12.3.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (13.5.2)\n",
      "Requirement already satisfied: starlette in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (0.27.0)\n",
      "Requirement already satisfied: starsessions<2.0,>=1.2.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (1.3.0)\n",
      "Requirement already satisfied: torch<4.0,>=1.11.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (2.0.1)\n",
      "Requirement already satisfied: torchmetrics<2.0,>=0.7.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (1.1.1)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (4.66.0)\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (5.9.0)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (4.7.1)\n",
      "Requirement already satisfied: urllib3<4.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (2.0.4)\n",
      "Requirement already satisfied: uvicorn<2.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (0.23.2)\n",
      "Requirement already satisfied: websocket-client<3.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (0.58.0)\n",
      "Requirement already satisfied: websockets<13.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (11.0.3)\n",
      "Requirement already satisfied: pytorch-lightning in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning) (2.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.3.2.post1)\n",
      "Requirement already satisfied: pytz in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from dateutils<2.0->lightning) (2023.3)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from deepdiff<8.0,>=5.7.0->lightning) (4.1.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from fsspec<2025.0,>=2022.5.0->lightning) (3.8.5)\n",
      "Requirement already satisfied: blessed>=1.19.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.20.0)\n",
      "Requirement already satisfied: python-editor>=1.0.4 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.0.4)\n",
      "Requirement already satisfied: readchar>=3.0.6 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (4.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from Jinja2<5.0->lightning) (2.1.1)\n",
      "Requirement already satisfied: pyjwt in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning-cloud>=0.5.37->lightning) (2.8.0)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from lightning-cloud>=0.5.37->lightning) (1.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from pydantic<2.2.0,>=1.7.4->lightning) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.4.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from pydantic<2.2.0,>=1.7.4->lightning) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from requests<4.0->lightning) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from requests<4.0->lightning) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from requests<4.0->lightning) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.16.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from starlette->lightning) (3.5.0)\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (3.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<4.0,>=1.11.0->lightning) (68.0.0)\n",
      "Requirement already satisfied: wheel in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<4.0,>=1.11.0->lightning) (0.38.4)\n",
      "Requirement already satisfied: cmake in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning) (3.27.2)\n",
      "Requirement already satisfied: lit in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning) (16.0.6)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (0.14.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.11.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: torch in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (68.0.0)\n",
      "Requirement already satisfied: wheel in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: cmake in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.27.2)\n",
      "Requirement already satisfied: lit in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: numpy in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torchvision) (1.22.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: bayesian-optimization in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from bayesian-optimization) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from bayesian-optimization) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from bayesian-optimization) (1.3.0)\n",
      "Requirement already satisfied: colorama>=0.4.6 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from bayesian-optimization) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install lightning\n",
    "# on mac\n",
    "!pip3 install torch torchvision torchaudio\n",
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():        \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional import accuracy, f1_score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davidson = pd.read_csv(\"datasets/davidson.csv\")\n",
    "davidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>care.virtue</th>\n",
       "      <th>care.vice</th>\n",
       "      <th>authority.virtue</th>\n",
       "      <th>fairness.vice</th>\n",
       "      <th>fairness.virtue</th>\n",
       "      <th>loyalty.vice</th>\n",
       "      <th>loyalty.virtue</th>\n",
       "      <th>sanctity.virtue</th>\n",
       "      <th>authority.vice</th>\n",
       "      <th>sanctity.vice</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.4113</td>\n",
       "      <td>0.5208</td>\n",
       "      <td>Partially Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.4309</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>Morally Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0609</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.2081</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>0.8027</td>\n",
       "      <td>Morally Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   care.virtue  care.vice  authority.virtue  fairness.vice  fairness.virtue  \\\n",
       "0          0.0        0.0               0.0            0.0              0.0   \n",
       "1          0.0        0.0               0.0            0.0              0.0   \n",
       "2          0.0        0.0               0.0            0.0              0.0   \n",
       "3          0.0        0.0               0.0            0.0              0.0   \n",
       "4          0.0        0.0               0.0            0.0              0.0   \n",
       "\n",
       "   loyalty.vice  loyalty.virtue  sanctity.virtue  authority.vice  \\\n",
       "0           0.0             0.0              0.5             0.0   \n",
       "1           0.0             0.0              0.0             0.0   \n",
       "2           0.0             0.0              0.0             0.0   \n",
       "3           0.0             0.0              0.0             0.0   \n",
       "4           0.0             0.0              0.0             0.0   \n",
       "\n",
       "   sanctity.vice  positive  neutral  negative                          target  \n",
       "0            1.0    0.0679   0.4113    0.5208              Partially Negative  \n",
       "1            0.0    0.0326   0.4309    0.5365  Neutral but Negative Sentiment  \n",
       "2            1.0    0.0031   0.0268    0.9701                Morally Negative  \n",
       "3            0.0    0.0609   0.7310    0.2081                         Neutral  \n",
       "4            1.0    0.0119   0.1853    0.8027                Morally Negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davidson_classes = pd.read_csv(\"datasets/edited/davidson_with_classes.csv\")\n",
    "davidson_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>Partially Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Morally Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>Morally Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                           target  \n",
       "0              Partially Negative  \n",
       "1  Neutral but Negative Sentiment  \n",
       "2                Morally Negative  \n",
       "3                         Neutral  \n",
       "4                Morally Negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_davidson = pd.DataFrame(davidson['tweet']).join(davidson_classes['target'])\n",
    "dataframe_davidson = dataframe_davidson.rename(columns={'tweet': 'text'})\n",
    "dataframe_davidson.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>bucket</th>\n",
       "      <th>annotator</th>\n",
       "      <th>annotation</th>\n",
       "      <th>confidence</th>\n",
       "      <th>care.virtue</th>\n",
       "      <th>care.vice</th>\n",
       "      <th>fairness.virtue</th>\n",
       "      <th>fairness.vice</th>\n",
       "      <th>loyalty.virtue</th>\n",
       "      <th>loyalty.vice</th>\n",
       "      <th>authority.virtue</th>\n",
       "      <th>authority.vice</th>\n",
       "      <th>sanctity.virtue</th>\n",
       "      <th>sanctity.vice</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That particular part of the debate is especial...</td>\n",
       "      <td>europe</td>\n",
       "      <td>French politics</td>\n",
       "      <td>annotator03</td>\n",
       "      <td>Non-Moral</td>\n",
       "      <td>Confident</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>particular debate especially funny macron expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/r/france is pretty lively, with it's own ling...</td>\n",
       "      <td>europe</td>\n",
       "      <td>French politics</td>\n",
       "      <td>annotator03</td>\n",
       "      <td>Non-Moral</td>\n",
       "      <td>Confident</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>r france pretty lively lingo usually delibera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TBH Marion Le Pen would be better. Closet fasc...</td>\n",
       "      <td>neoliberal</td>\n",
       "      <td>French politics</td>\n",
       "      <td>annotator03</td>\n",
       "      <td>Non-Moral</td>\n",
       "      <td>Somewhat Confident</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tbh marion le pen well closet fascist vs flamb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it really is a very unusual situation isn't it...</td>\n",
       "      <td>europe</td>\n",
       "      <td>French politics</td>\n",
       "      <td>annotator03</td>\n",
       "      <td>Non-Moral</td>\n",
       "      <td>Confident</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unusual situation fillon affair influence vote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Le Pen brand of conservatism and classical...</td>\n",
       "      <td>europe</td>\n",
       "      <td>French politics</td>\n",
       "      <td>annotator03</td>\n",
       "      <td>Authority</td>\n",
       "      <td>Somewhat Confident</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>le pen brand conservatism classical right wing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   subreddit  \\\n",
       "0  That particular part of the debate is especial...      europe   \n",
       "1  /r/france is pretty lively, with it's own ling...      europe   \n",
       "2  TBH Marion Le Pen would be better. Closet fasc...  neoliberal   \n",
       "3  it really is a very unusual situation isn't it...      europe   \n",
       "4  The Le Pen brand of conservatism and classical...      europe   \n",
       "\n",
       "            bucket    annotator annotation          confidence  care.virtue  \\\n",
       "0  French politics  annotator03  Non-Moral           Confident            0   \n",
       "1  French politics  annotator03  Non-Moral           Confident            0   \n",
       "2  French politics  annotator03  Non-Moral  Somewhat Confident            0   \n",
       "3  French politics  annotator03  Non-Moral           Confident            0   \n",
       "4  French politics  annotator03  Authority  Somewhat Confident            0   \n",
       "\n",
       "   care.vice  fairness.virtue  fairness.vice  loyalty.virtue  loyalty.vice  \\\n",
       "0          0                0              0               0             0   \n",
       "1          0                0              0               0             0   \n",
       "2          0                0              0               0             0   \n",
       "3          0                0              0               0             0   \n",
       "4          0                0              0               0             0   \n",
       "\n",
       "   authority.virtue  authority.vice  sanctity.virtue  sanctity.vice  \\\n",
       "0                 0               0                0              0   \n",
       "1                 0               0                0              0   \n",
       "2                 0               0                0              0   \n",
       "3                 0               0                0              0   \n",
       "4                 0               0                0              0   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  particular debate especially funny macron expl...  \n",
       "1   r france pretty lively lingo usually delibera...  \n",
       "2  tbh marion le pen well closet fascist vs flamb...  \n",
       "3  unusual situation fillon affair influence vote...  \n",
       "4  le pen brand conservatism classical right wing...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfrc = pd.read_csv(\"datasets/edited/mfrc_reduced.csv\")\n",
    "mfrc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>care.virtue</th>\n",
       "      <th>care.vice</th>\n",
       "      <th>authority.virtue</th>\n",
       "      <th>fairness.vice</th>\n",
       "      <th>fairness.virtue</th>\n",
       "      <th>loyalty.vice</th>\n",
       "      <th>loyalty.virtue</th>\n",
       "      <th>sanctity.virtue</th>\n",
       "      <th>authority.vice</th>\n",
       "      <th>sanctity.vice</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.3189</td>\n",
       "      <td>0.5743</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5590</td>\n",
       "      <td>0.2707</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.4460</td>\n",
       "      <td>0.4882</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.3472</td>\n",
       "      <td>0.6324</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.7794</td>\n",
       "      <td>0.1751</td>\n",
       "      <td>Morally Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   care.virtue  care.vice  authority.virtue  fairness.vice  fairness.virtue  \\\n",
       "0          0.0        0.0               0.0            0.0              0.0   \n",
       "1          0.0        0.0               0.0            0.0              0.0   \n",
       "2          0.0        0.0               0.0            0.0              0.0   \n",
       "3          0.0        0.0               0.0            0.0              0.0   \n",
       "4          0.0        0.0               0.0            0.0              0.0   \n",
       "\n",
       "   loyalty.vice  loyalty.virtue  sanctity.virtue  authority.vice  \\\n",
       "0           0.0        0.000000         0.000000             0.0   \n",
       "1           0.0        0.000000         0.000000             0.0   \n",
       "2           0.0        0.000000         0.000000             0.0   \n",
       "3           0.0        0.000000         0.000000             0.0   \n",
       "4           0.0        0.333333         0.666667             0.0   \n",
       "\n",
       "   sanctity.vice  positive  neutral  negative                          target  \n",
       "0            0.0    0.1067   0.3189    0.5743  Neutral but Negative Sentiment  \n",
       "1            0.0    0.1703   0.5590    0.2707                         Neutral  \n",
       "2            0.0    0.0658   0.4460    0.4882  Neutral but Negative Sentiment  \n",
       "3            0.0    0.0204   0.3472    0.6324  Neutral but Negative Sentiment  \n",
       "4            0.0    0.0455   0.7794    0.1751                Morally Positive  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfrc_classes = pd.read_csv(\"datasets/edited/mfrc_with_classes.csv\")\n",
    "mfrc_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That particular part of the debate is especial...</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/r/france is pretty lively, with it's own ling...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TBH Marion Le Pen would be better. Closet fasc...</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it really is a very unusual situation isn't it...</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Le Pen brand of conservatism and classical...</td>\n",
       "      <td>Morally Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  That particular part of the debate is especial...   \n",
       "1  /r/france is pretty lively, with it's own ling...   \n",
       "2  TBH Marion Le Pen would be better. Closet fasc...   \n",
       "3  it really is a very unusual situation isn't it...   \n",
       "4  The Le Pen brand of conservatism and classical...   \n",
       "\n",
       "                           target  \n",
       "0  Neutral but Negative Sentiment  \n",
       "1                         Neutral  \n",
       "2  Neutral but Negative Sentiment  \n",
       "3  Neutral but Negative Sentiment  \n",
       "4                Morally Positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_mfrc = pd.DataFrame(mfrc['text']).join(mfrc_classes['target'])\n",
    "dataframe_mfrc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>Partially Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Morally Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>Morally Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42664</th>\n",
       "      <td>My job is actually ok and I work with loads of...</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42665</th>\n",
       "      <td>Someone dying of a disease doesn't change that...</td>\n",
       "      <td>Morally Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42666</th>\n",
       "      <td>Some of these politicians and commentators tak...</td>\n",
       "      <td>Morally Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42667</th>\n",
       "      <td>No, it's \"truth over facts! Wait where am I ag...</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42668</th>\n",
       "      <td>I feel this. I too would like to just be a bea...</td>\n",
       "      <td>Morally Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42669 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "...                                                  ...   \n",
       "42664  My job is actually ok and I work with loads of...   \n",
       "42665  Someone dying of a disease doesn't change that...   \n",
       "42666  Some of these politicians and commentators tak...   \n",
       "42667  No, it's \"truth over facts! Wait where am I ag...   \n",
       "42668  I feel this. I too would like to just be a bea...   \n",
       "\n",
       "                               target  \n",
       "0                  Partially Negative  \n",
       "1      Neutral but Negative Sentiment  \n",
       "2                    Morally Negative  \n",
       "3                             Neutral  \n",
       "4                    Morally Negative  \n",
       "...                               ...  \n",
       "42664  Neutral but Negative Sentiment  \n",
       "42665                Morally Negative  \n",
       "42666                Morally Negative  \n",
       "42667  Neutral but Negative Sentiment  \n",
       "42668                Morally Negative  \n",
       "\n",
       "[42669 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([dataframe_davidson, dataframe_mfrc]).reset_index()\n",
    "del df['index']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>encoded_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>Partially Negative</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Morally Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>Morally Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42664</th>\n",
       "      <td>My job is actually ok and I work with loads of...</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42665</th>\n",
       "      <td>Someone dying of a disease doesn't change that...</td>\n",
       "      <td>Morally Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42666</th>\n",
       "      <td>Some of these politicians and commentators tak...</td>\n",
       "      <td>Morally Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42667</th>\n",
       "      <td>No, it's \"truth over facts! Wait where am I ag...</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42668</th>\n",
       "      <td>I feel this. I too would like to just be a bea...</td>\n",
       "      <td>Morally Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42669 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "...                                                  ...   \n",
       "42664  My job is actually ok and I work with loads of...   \n",
       "42665  Someone dying of a disease doesn't change that...   \n",
       "42666  Some of these politicians and commentators tak...   \n",
       "42667  No, it's \"truth over facts! Wait where am I ag...   \n",
       "42668  I feel this. I too would like to just be a bea...   \n",
       "\n",
       "                               target  encoded_target  \n",
       "0                  Partially Negative               5  \n",
       "1      Neutral but Negative Sentiment               3  \n",
       "2                    Morally Negative               0  \n",
       "3                             Neutral               2  \n",
       "4                    Morally Negative               0  \n",
       "...                               ...             ...  \n",
       "42664  Neutral but Negative Sentiment               3  \n",
       "42665                Morally Negative               0  \n",
       "42666                Morally Negative               0  \n",
       "42667  Neutral but Negative Sentiment               3  \n",
       "42668                Morally Negative               0  \n",
       "\n",
       "[42669 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.join(pd.get_dummies(df['target'], dtype = float))\n",
    "# del df['target']\n",
    "# df\n",
    "\n",
    "df['encoded_target'] = df.target.astype('category').cat.codes\n",
    "# df.target = df.target.astype('float')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>encoded_target</th>\n",
       "      <th>care.virtue</th>\n",
       "      <th>care.vice</th>\n",
       "      <th>authority.virtue</th>\n",
       "      <th>fairness.vice</th>\n",
       "      <th>fairness.virtue</th>\n",
       "      <th>loyalty.vice</th>\n",
       "      <th>loyalty.virtue</th>\n",
       "      <th>sanctity.virtue</th>\n",
       "      <th>authority.vice</th>\n",
       "      <th>sanctity.vice</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>Partially Negative</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.4113</td>\n",
       "      <td>0.5208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.4309</td>\n",
       "      <td>0.5365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Morally Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.9701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0609</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.2081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>Morally Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>0.8027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42664</th>\n",
       "      <td>My job is actually ok and I work with loads of...</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.7494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42665</th>\n",
       "      <td>Someone dying of a disease doesn't change that...</td>\n",
       "      <td>Morally Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1579</td>\n",
       "      <td>0.8321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42666</th>\n",
       "      <td>Some of these politicians and commentators tak...</td>\n",
       "      <td>Morally Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.2494</td>\n",
       "      <td>0.7321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42667</th>\n",
       "      <td>No, it's \"truth over facts! Wait where am I ag...</td>\n",
       "      <td>Neutral but Negative Sentiment</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.4317</td>\n",
       "      <td>0.5214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42668</th>\n",
       "      <td>I feel this. I too would like to just be a bea...</td>\n",
       "      <td>Morally Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.4571</td>\n",
       "      <td>0.3289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42669 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "...                                                  ...   \n",
       "42664  My job is actually ok and I work with loads of...   \n",
       "42665  Someone dying of a disease doesn't change that...   \n",
       "42666  Some of these politicians and commentators tak...   \n",
       "42667  No, it's \"truth over facts! Wait where am I ag...   \n",
       "42668  I feel this. I too would like to just be a bea...   \n",
       "\n",
       "                               target  encoded_target  care.virtue  care.vice  \\\n",
       "0                  Partially Negative               5          0.0        0.0   \n",
       "1      Neutral but Negative Sentiment               3          0.0        0.0   \n",
       "2                    Morally Negative               0          0.0        0.0   \n",
       "3                             Neutral               2          0.0        0.0   \n",
       "4                    Morally Negative               0          0.0        0.0   \n",
       "...                               ...             ...          ...        ...   \n",
       "42664  Neutral but Negative Sentiment               3          0.0        0.0   \n",
       "42665                Morally Negative               0          0.0        0.0   \n",
       "42666                Morally Negative               0          0.0        0.0   \n",
       "42667  Neutral but Negative Sentiment               3          0.0        0.0   \n",
       "42668                Morally Negative               0          0.0        0.0   \n",
       "\n",
       "       authority.virtue  fairness.vice  fairness.virtue  loyalty.vice  \\\n",
       "0                   0.0            0.0              0.0           0.0   \n",
       "1                   0.0            0.0              0.0           0.0   \n",
       "2                   0.0            0.0              0.0           0.0   \n",
       "3                   0.0            0.0              0.0           0.0   \n",
       "4                   0.0            0.0              0.0           0.0   \n",
       "...                 ...            ...              ...           ...   \n",
       "42664               0.0            0.0              0.0           0.0   \n",
       "42665               0.0            0.0              0.0           0.0   \n",
       "42666               0.0            1.0              0.0           0.0   \n",
       "42667               0.0            0.0              0.0           0.0   \n",
       "42668               0.0            0.0              0.0           0.0   \n",
       "\n",
       "       loyalty.virtue  sanctity.virtue  authority.vice  sanctity.vice  \\\n",
       "0                 0.0              0.5             0.0            1.0   \n",
       "1                 0.0              0.0             0.0            0.0   \n",
       "2                 0.0              0.0             0.0            1.0   \n",
       "3                 0.0              0.0             0.0            0.0   \n",
       "4                 0.0              0.0             0.0            1.0   \n",
       "...               ...              ...             ...            ...   \n",
       "42664             0.0              0.0             0.0            0.0   \n",
       "42665             0.0              0.0             0.0            1.0   \n",
       "42666             0.0              0.0             0.0            0.0   \n",
       "42667             0.0              0.0             0.0            0.0   \n",
       "42668             0.0              0.0             0.0            1.0   \n",
       "\n",
       "       positive  neutral  negative  \n",
       "0        0.0679   0.4113    0.5208  \n",
       "1        0.0326   0.4309    0.5365  \n",
       "2        0.0031   0.0268    0.9701  \n",
       "3        0.0609   0.7310    0.2081  \n",
       "4        0.0119   0.1853    0.8027  \n",
       "...         ...      ...       ...  \n",
       "42664    0.0765   0.1741    0.7494  \n",
       "42665    0.0100   0.1579    0.8321  \n",
       "42666    0.0186   0.2494    0.7321  \n",
       "42667    0.0470   0.4317    0.5214  \n",
       "42668    0.2140   0.4571    0.3289  \n",
       "\n",
       "[42669 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"datasets/edited/davidson_with_classes.csv\")\n",
    "del data1['target']\n",
    "data2 = pd.read_csv(\"datasets/edited/mfrc_with_classes.csv\")\n",
    "del data2['target']\n",
    "data = pd.concat([data1, data2]).reset_index()\n",
    "df = df.join(data)\n",
    "del df['index']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['care.virtue', 'care.vice', 'authority.virtue', 'fairness.vice', 'fairness.virtue', 'loyalty.vice', 'loyalty.virtue', 'sanctity.virtue', 'authority.vice', 'sanctity.vice', 'positive', 'neutral', 'negative']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Partially Negative': 5,\n",
       " 'Neutral but Negative Sentiment': 3,\n",
       " 'Morally Negative': 0,\n",
       " 'Neutral': 2,\n",
       " 'Morally Positive': 1,\n",
       " 'Neutral but Positive Sentiment': 4,\n",
       " 'Partially Neutral': 6,\n",
       " 'Partially Positive': 7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCORE_COLUMNS = df.columns.tolist()[3:]\n",
    "print(SCORE_COLUMNS)\n",
    "\n",
    "LABELS_DICT = dict()\n",
    "for i in df.index:\n",
    "    LABELS_DICT[df['target'][i]] = df['encoded_target'][i]\n",
    "\n",
    "LABELS_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.trainer.trainer import Trainer\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=\"checkpoints\",\n",
    "  filename=\"best-checkpoint-{val_loss:.2f}\",\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "  callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "  max_epochs=15,\n",
    "  accelerator=\"gpu\",\n",
    "  devices=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79eba78a92b5420f8a125ffbb1c00d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.0003019951720402019\n",
      "Restoring states from the checkpoint path at /home/roberto/Desktop/git-repos/Fair-NLP/.lr_find_798e3737-8a5b-4384-a75d-327a9ddec4b5.ckpt\n",
      "Restored all states from the checkpoint at /home/roberto/Desktop/git-repos/Fair-NLP/.lr_find_798e3737-8a5b-4384-a75d-327a9ddec4b5.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type                | Params\n",
      "-----------------------------------------------------------\n",
      "0 | bert               | BertModel           | 109 M \n",
      "1 | classifier         | Linear              | 6.2 K \n",
      "2 | criterion          | CrossEntropyLoss    | 0     \n",
      "3 | weighted_accuracy  | MulticlassAccuracy  | 0     \n",
      "4 | weighted_precision | MulticlassPrecision | 0     \n",
      "5 | weighted_recall    | MulticlassRecall    | 0     \n",
      "6 | weighted_f1        | MulticlassF1Score   | 0     \n",
      "-----------------------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.954   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd9c3aec6604f159bc353d5d4b34669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab91b643e97042ce97822cef7d0491ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c5b0df68984521bff158e45ac263da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 2986: 'val_loss' reached 1.66267 (best 1.66267), saving model to '/home/roberto/Desktop/git-repos/Fair-NLP/checkpoints/best-checkpoint-val_loss=1.66.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed9df591dbc4d71aee03b8a0218c86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 5972: 'val_loss' reached 1.66059 (best 1.66059), saving model to '/home/roberto/Desktop/git-repos/Fair-NLP/checkpoints/best-checkpoint-val_loss=1.66.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f477ef17c2284abbb2d5a0c4614eae79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 8958: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caae1c8cca814e36b82b6b35a4510e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 11944: 'val_loss' reached 1.66045 (best 1.66045), saving model to '/home/roberto/Desktop/git-repos/Fair-NLP/checkpoints/best-checkpoint-val_loss=1.66.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f4b8ea842c445d8d976a0064d6bfcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 14930: 'val_loss' reached 1.66018 (best 1.66018), saving model to '/home/roberto/Desktop/git-repos/Fair-NLP/checkpoints/best-checkpoint-val_loss=1.66.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc91d3c498d441cab2cd39407eb929b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 17916: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d2867d76f34146b5586fac1f9b5cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 20902: 'val_loss' reached 1.65958 (best 1.65958), saving model to '/home/roberto/Desktop/git-repos/Fair-NLP/checkpoints/best-checkpoint-val_loss=1.66.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3716c9ff45ac41c882790b63055b7fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 23888: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11bd958565345168216f88cf2f0746e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 26874: 'val_loss' reached 1.65911 (best 1.65911), saving model to '/home/roberto/Desktop/git-repos/Fair-NLP/checkpoints/best-checkpoint-val_loss=1.66.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe68bd870a494d06a72648c5cd8f68fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 29860: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082ac3ca94c34a2081742e13aab71229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 32846: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8147f22d2a4be585adc54ba64c2521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 35832: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707ca23c4e97498393bd37d9af2f1546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 38818: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30ad9c8577a4daab58dcf940dbf60c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 41804: 'val_loss' was not in top 1\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bec92dbfefa427b8f01f48cf1507663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3359906077384949     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1869634985923767     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.6454944610595703     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_prec         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1339273750782013     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_rec          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3359906077384949     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3359906077384949    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1869634985923767    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.6454944610595703    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_prec        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1339273750782013    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_rec         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3359906077384949    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7a4753c1be476a9663f2b70c5f7f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.33568075299263      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18825191259384155    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.625611424446106     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_prec          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13596247136592865    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_rec          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.33568075299263      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.33568075299263     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18825191259384155   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.625611424446106    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_prec         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13596247136592865   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_rec         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.33568075299263     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 1.625611424446106,\n",
       "  'val_acc': 0.33568075299263,\n",
       "  'val_prec': 0.13596247136592865,\n",
       "  'val_rec': 0.33568075299263,\n",
       "  'val_f1': 0.18825191259384155}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.dataset_torch import CustomDataModule, CustomDataset, Model\n",
    "from transformers import AutoTokenizer\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "\n",
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "model = Model(BERT_MODEL_NAME, lr = 2e-5, weigth_decay=0.001)\n",
    "datamodule = CustomDataModule(df, tokenizer, batch_size=10)\n",
    "\n",
    "tuner = Tuner(trainer)\n",
    "lr_finder = tuner.lr_find(model, datamodule=datamodule, early_stop_threshold=None)\n",
    "model.lr = lr_finder.suggestion()\n",
    "model = Model(BERT_MODEL_NAME, lr = lr_finder.suggestion(), weigth_decay=0.001)\n",
    "\n",
    "trainer.fit(model=model, \n",
    "            datamodule=datamodule)\n",
    "trainer.test(model=model, datamodule=datamodule)\n",
    "trainer.validate(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /home/roberto/Desktop/git-repos/Fair-NLP/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutput' object has no attribute 'pooler_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m datamodule \u001b[39m=\u001b[39m CustomDataModule(df, tokenizer, batch_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m     11\u001b[0m tuner \u001b[39m=\u001b[39m Tuner(trainer)\n\u001b[0;32m---> 12\u001b[0m lr_finder \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39;49mlr_find(model, datamodule\u001b[39m=\u001b[39;49mdatamodule, early_stop_threshold\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     13\u001b[0m model\u001b[39m.\u001b[39mlr \u001b[39m=\u001b[39m lr_finder\u001b[39m.\u001b[39msuggestion()\n\u001b[1;32m     14\u001b[0m model \u001b[39m=\u001b[39m Model(BERT_MODEL_NAME, lr \u001b[39m=\u001b[39m lr_finder\u001b[39m.\u001b[39msuggestion(), weigth_decay\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/tuner/tuning.py:177\u001b[0m, in \u001b[0;36mTuner.lr_find\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, dataloaders, datamodule, method, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr, attr_name)\u001b[0m\n\u001b[1;32m    174\u001b[0m lr_finder_callback\u001b[39m.\u001b[39m_early_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer\u001b[39m.\u001b[39mcallbacks \u001b[39m=\u001b[39m [lr_finder_callback] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer\u001b[39m.\u001b[39mcallbacks\n\u001b[0;32m--> 177\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_trainer\u001b[39m.\u001b[39;49mfit(model, train_dataloaders, val_dataloaders, datamodule)\n\u001b[1;32m    179\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer\u001b[39m.\u001b[39mcallbacks \u001b[39m=\u001b[39m [cb \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer\u001b[39m.\u001b[39mcallbacks \u001b[39mif\u001b[39;00m cb \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lr_finder_callback]\n\u001b[1;32m    181\u001b[0m \u001b[39mreturn\u001b[39;00m lr_finder_callback\u001b[39m.\u001b[39moptimal_lr\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[0;32m--> 532\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    533\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    534\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    562\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    567\u001b[0m     ckpt_path,\n\u001b[1;32m    568\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m )\n\u001b[0;32m--> 571\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:960\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mFITTING:\n\u001b[0;32m--> 960\u001b[0m     call\u001b[39m.\u001b[39;49m_call_callback_hooks(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mon_fit_start\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    961\u001b[0m     call\u001b[39m.\u001b[39m_call_lightning_module_hook(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_fit_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    963\u001b[0m _log_hyperparams(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:194\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(fn):\n\u001b[1;32m    193\u001b[0m         \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Callback]\u001b[39m\u001b[39m{\u001b[39;00mcallback\u001b[39m.\u001b[39mstate_key\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 194\u001b[0m             fn(trainer, trainer\u001b[39m.\u001b[39;49mlightning_module, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    196\u001b[0m \u001b[39mif\u001b[39;00m pl_module:\n\u001b[1;32m    197\u001b[0m     \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/callbacks/lr_finder.py:125\u001b[0m, in \u001b[0;36mLearningRateFinder.on_fit_start\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_fit_start\u001b[39m(\u001b[39mself\u001b[39m, trainer: \u001b[39m\"\u001b[39m\u001b[39mpl.Trainer\u001b[39m\u001b[39m\"\u001b[39m, pl_module: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlr_find(trainer, pl_module)\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/callbacks/lr_finder.py:109\u001b[0m, in \u001b[0;36mLearningRateFinder.lr_find\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlr_find\u001b[39m(\u001b[39mself\u001b[39m, trainer: \u001b[39m\"\u001b[39m\u001b[39mpl.Trainer\u001b[39m\u001b[39m\"\u001b[39m, pl_module: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m--> 109\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimal_lr \u001b[39m=\u001b[39m _lr_find(\n\u001b[1;32m    110\u001b[0m             trainer,\n\u001b[1;32m    111\u001b[0m             pl_module,\n\u001b[1;32m    112\u001b[0m             min_lr\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_min_lr,\n\u001b[1;32m    113\u001b[0m             max_lr\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_max_lr,\n\u001b[1;32m    114\u001b[0m             num_training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_training_steps,\n\u001b[1;32m    115\u001b[0m             mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mode,\n\u001b[1;32m    116\u001b[0m             early_stop_threshold\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_early_stop_threshold,\n\u001b[1;32m    117\u001b[0m             update_attr\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_attr,\n\u001b[1;32m    118\u001b[0m             attr_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_attr_name,\n\u001b[1;32m    119\u001b[0m         )\n\u001b[1;32m    121\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_early_exit:\n\u001b[1;32m    122\u001b[0m         \u001b[39mraise\u001b[39;00m _TunerExitException()\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/tuner/lr_finder.py:272\u001b[0m, in \u001b[0;36m_lr_find\u001b[0;34m(trainer, model, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr, attr_name)\u001b[0m\n\u001b[1;32m    269\u001b[0m lr_finder\u001b[39m.\u001b[39m_exchange_scheduler(trainer)\n\u001b[1;32m    271\u001b[0m \u001b[39m# Fit, lr & loss logged in callback\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m _try_loop_run(trainer, params)\n\u001b[1;32m    274\u001b[0m \u001b[39m# Prompt if we stopped early\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mglobal_step \u001b[39m!=\u001b[39m num_training \u001b[39m+\u001b[39m start_steps:\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/tuner/lr_finder.py:512\u001b[0m, in \u001b[0;36m_try_loop_run\u001b[0;34m(trainer, params)\u001b[0m\n\u001b[1;32m    510\u001b[0m loop\u001b[39m.\u001b[39mload_state_dict(deepcopy(params[\u001b[39m\"\u001b[39m\u001b[39mloop_state_dict\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m    511\u001b[0m loop\u001b[39m.\u001b[39mrestarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 512\u001b[0m loop\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance()\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:355\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(combined_loader)\n\u001b[1;32m    354\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:134\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance(data_fetcher)\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_advance_end()\n\u001b[1;32m    135\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:249\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.on_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mif\u001b[39;00m should_check_val:\n\u001b[1;32m    248\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mvalidating \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mval_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m    250\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39m# update plateau LR scheduler after metrics are logged\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m    180\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m     previous_dataloader_idx \u001b[39m=\u001b[39m dataloader_idx\n\u001b[1;32m    114\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx)\n\u001b[1;32m    116\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:376\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    375\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 376\u001b[0m output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, hook_name, \u001b[39m*\u001b[39;49mstep_kwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    378\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    380\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_test_batch_end\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mon_validation_batch_end\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:293\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    295\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    296\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:393\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[1;32m    392\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, ValidationStep)\n\u001b[0;32m--> 393\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/git-repos/Fair-NLP/utils/dataset_torch.py:251\u001b[0m, in \u001b[0;36mModel.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    249\u001b[0m attention_mask \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    250\u001b[0m labels \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 251\u001b[0m loss, outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(input_ids, attention_mask, labels)\n\u001b[1;32m    252\u001b[0m \u001b[39m# self.log(\"val_loss\", loss, prog_bar=True, logger=True)\u001b[39;00m\n\u001b[1;32m    254\u001b[0m accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweighted_accuracy(outputs, labels)\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/git-repos/Fair-NLP/utils/dataset_torch.py:215\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, input_ids, attention_mask, label)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, attention_mask, label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    214\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert(input_ids, attention_mask\u001b[39m=\u001b[39mattention_mask)\n\u001b[0;32m--> 215\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(output\u001b[39m.\u001b[39;49mpooler_output)\n\u001b[1;32m    216\u001b[0m     \u001b[39m# output = torch.sigmoid(output)\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# output = torch.softmax(output, dim=1)\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseModelOutput' object has no attribute 'pooler_output'"
     ]
    }
   ],
   "source": [
    "from utils.dataset_torch import CustomDataModule, CustomDataset, Model\n",
    "from transformers import AutoTokenizer\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "BERT_MODEL_NAME = 'distilbert-base-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "model = Model(BERT_MODEL_NAME, lr = 2e-5, weigth_decay=0.001)\n",
    "datamodule = CustomDataModule(df, tokenizer, batch_size=10)\n",
    "\n",
    "tuner = Tuner(trainer)\n",
    "lr_finder = tuner.lr_find(model, datamodule=datamodule, early_stop_threshold=None)\n",
    "model.lr = lr_finder.suggestion()\n",
    "model = Model(BERT_MODEL_NAME, lr = lr_finder.suggestion(), weigth_decay=0.001)\n",
    "\n",
    "trainer.fit(model=model, \n",
    "            datamodule=datamodule)\n",
    "trainer.test(model=model, datamodule=datamodule)\n",
    "trainer.validate(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearLR' object has no attribute 'lr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m datamodule \u001b[39m=\u001b[39m CustomDataModule(df, tokenizer, batch_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39m# tuner = Tuner(trainer)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# lr_finder = tuner.lr_find(model, datamodule=datamodule, early_stop_threshold=None)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# model.lr = lr_finder.suggestion()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# model = Model(BERT_MODEL_NAME, lr = lr_finder.suggestion(), weigth_decay=0.001)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model\u001b[39m=\u001b[39;49mmodel, \n\u001b[1;32m     17\u001b[0m             datamodule\u001b[39m=\u001b[39;49mdatamodule)\n\u001b[1;32m     18\u001b[0m trainer\u001b[39m.\u001b[39mtest(model\u001b[39m=\u001b[39mmodel, datamodule\u001b[39m=\u001b[39mdatamodule)\n\u001b[1;32m     19\u001b[0m trainer\u001b[39m.\u001b[39mvalidate(model, datamodule\u001b[39m=\u001b[39mdatamodule)\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[0;32m--> 532\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    533\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    534\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    562\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    567\u001b[0m     ckpt_path,\n\u001b[1;32m    568\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m )\n\u001b[0;32m--> 571\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    982\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1022\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1023\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1024\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected state \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance()\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:355\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(combined_loader)\n\u001b[1;32m    354\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:133\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(data_fetcher)\n\u001b[1;32m    134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:207\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warning_cache\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mtrain_dataloader yielded None. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39m# hook\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m     call\u001b[39m.\u001b[39;49m_call_callback_hooks(trainer, \u001b[39m\"\u001b[39;49m\u001b[39mon_train_batch_start\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, batch_idx)\n\u001b[1;32m    208\u001b[0m     response \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39m_call_lightning_module_hook(trainer, \u001b[39m\"\u001b[39m\u001b[39mon_train_batch_start\u001b[39m\u001b[39m\"\u001b[39m, batch, batch_idx)\n\u001b[1;32m    209\u001b[0m     call\u001b[39m.\u001b[39m_call_strategy_hook(trainer, \u001b[39m\"\u001b[39m\u001b[39mon_train_batch_start\u001b[39m\u001b[39m\"\u001b[39m, batch, batch_idx)\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:194\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(fn):\n\u001b[1;32m    193\u001b[0m         \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Callback]\u001b[39m\u001b[39m{\u001b[39;00mcallback\u001b[39m.\u001b[39mstate_key\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 194\u001b[0m             fn(trainer, trainer\u001b[39m.\u001b[39;49mlightning_module, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    196\u001b[0m \u001b[39mif\u001b[39;00m pl_module:\n\u001b[1;32m    197\u001b[0m     \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/opt/anaconda/envs/tf_gpu/lib/python3.10/site-packages/lightning/pytorch/tuner/lr_finder.py:389\u001b[0m, in \u001b[0;36m_LRCallback.on_train_batch_start\u001b[0;34m(self, trainer, pl_module, batch, batch_idx)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_bar_refresh_rate \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_bar \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_bar \u001b[39m=\u001b[39m tqdm(desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFinding best initial lr\u001b[39m\u001b[39m\"\u001b[39m, total\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_training)\n\u001b[0;32m--> 389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlrs\u001b[39m.\u001b[39mappend(trainer\u001b[39m.\u001b[39;49mlr_scheduler_configs[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mscheduler\u001b[39m.\u001b[39;49mlr[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearLR' object has no attribute 'lr'"
     ]
    }
   ],
   "source": [
    "from utils.dataset_torch import CustomDataModule, CustomDataset, Model\n",
    "from transformers import AutoTokenizer\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "BERT_MODEL_NAME = 'roberta-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "model = Model(BERT_MODEL_NAME, lr = 2e-5, weigth_decay=0.001)\n",
    "datamodule = CustomDataModule(df, tokenizer, batch_size=10)\n",
    "\n",
    "# tuner = Tuner(trainer)\n",
    "# lr_finder = tuner.lr_find(model, datamodule=datamodule, early_stop_threshold=None)\n",
    "# model.lr = lr_finder.suggestion()\n",
    "# model = Model(BERT_MODEL_NAME, lr = lr_finder.suggestion(), weigth_decay=0.001)\n",
    "\n",
    "trainer.fit(model=model, \n",
    "            datamodule=datamodule)\n",
    "trainer.test(model=model, datamodule=datamodule)\n",
    "trainer.validate(model, datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
